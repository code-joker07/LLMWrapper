{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1USHfge29zAeKt3MQ7iFH-f5ox-a-Lt3o","timestamp":1692492763571}],"authorship_tag":"ABX9TyP46kwXRMzMyuK5j/PdnTNm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVWt9A_AEeQs","executionInfo":{"status":"ok","timestamp":1692492599816,"user_tz":-330,"elapsed":6653,"user":{"displayName":"Dibyajit Bag","userId":"04835751879796795025"}},"outputId":"c27e9f02-fe82-4afd-e6c5-34ee405da213"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"]}],"source":["pip install openai"]},{"cell_type":"code","source":["import openai\n","import time\n","\n","# Initialize the OpenAI API with your key\n","openai.api_key = 'Give your API Key'\n","\n","class LLMWrapper:\n","    MAX_TOKENS = 2048\n","    RATE_LIMIT_SLEEP_DURATION = 10\n","\n","    def __init__(self):\n","        self.conversation_history = []\n","        self.current_prompt = {}\n","\n","    def call_llm_api(self, text):\n","        if len(text) > LLMWrapper.MAX_TOKENS:\n","            raise ValueError(\"Token Limit Exceeded!\")\n","\n","        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n","\n","        # Add history to the messages\n","        for entry in self.conversation_history:\n","            messages.append({\"role\": \"user\", \"content\": entry['user']})\n","            messages.append({\"role\": \"assistant\", \"content\": entry['llm']})\n","\n","        # Add current user input last\n","        messages.append({\"role\": \"user\", \"content\": text})\n","\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-3.5-turbo\",\n","            messages=messages,\n","            max_tokens=500\n","        )\n","\n","        return response.choices[0].message['content'].strip()\n","\n","    def format_prompt(self):\n","        return \"; \".join([f\"{k}: {v}\" for k, v in self.current_prompt.items()])\n","\n","    def update_prompt_variables(self, new_variables):\n","        self.current_prompt.update(new_variables)\n","\n","    def add_to_history(self, user_input, llm_response):\n","        self.conversation_history.append({\n","            \"user\": user_input,\n","            \"llm\": llm_response,\n","            \"prompt\": self.format_prompt()\n","        })\n","\n","    def get_formatted_conversation(self):\n","        return \"\\n\".join([f\"User: {entry['user']}\\nLLM: {entry['llm']}\\nPrompt: {entry['prompt']}\" for entry in self.conversation_history])\n","\n","    def handle_rate_limit_error(self):\n","        print(\"Rate Limit Error! Waiting...\")\n","        time.sleep(LLMWrapper.RATE_LIMIT_SLEEP_DURATION)\n","\n","    def handle_token_limit_error(self):\n","        while len(self.get_formatted_conversation() + self.format_prompt()) > LLMWrapper.MAX_TOKENS:\n","            self.conversation_history.pop(0)\n","\n","    def send_to_llm(self, user_input, **prompt_variables):\n","        self.update_prompt_variables(prompt_variables)\n","\n","        while True:\n","            try:\n","                self.handle_token_limit_error()\n","                llm_response = self.call_llm_api(user_input)\n","                self.add_to_history(user_input, llm_response)\n","                return llm_response\n","            except ValueError as e:\n","                if \"Token Limit Exceeded\" in str(e):\n","                    self.handle_token_limit_error()\n","                else:\n","                    raise e\n","            except Exception as e:\n","                if \"rate limit\" in str(e).lower():\n","                    self.handle_rate_limit_error()\n","                else:\n","                    raise e\n","\n","# Usage\n","wrapper = LLMWrapper()\n","\n","while True:\n","    user_input = input(\"You: \")\n","    if user_input.lower() == \"exit\":\n","        break\n","\n","    prompt_variables = {}\n","\n","    response = wrapper.send_to_llm(user_input, **prompt_variables)\n","    print(f\"LLM: {response}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTbkrg8yEogI","executionInfo":{"status":"ok","timestamp":1692492722787,"user_tz":-330,"elapsed":122974,"user":{"displayName":"Dibyajit Bag","userId":"04835751879796795025"}},"outputId":"fe48933e-b8b1-485f-9472-4712e5288f8d"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["You: Hello\n","LLM: Hi there! How can I assist you today?\n","\n","You: Let X = 1\n","LLM: Great! X is now equal to 1. What would you like to do with this value of X?\n","\n","You: Now Consider Y = X + 10\n","LLM: Alright, if X = 1, then Y would be equal to 11 (since Y = X + 10). Is there anything else you would like me to help you with regarding these variables?\n","\n","You: Z = Y + X - 11\n","LLM: Got it! If Y = 11 and X = 1, then Z would be equal to 11 + 1 - 11, which simplifies to 1. Is there anything else you would like me to assist you with?\n","\n","You: Value of Z = ?\n","LLM: Based on the given values of X=1 and Y=11, the value of Z would be 1.\n","\n","You: exit\n"]}]}]}